package parquet

import (
	"encoding/json"
	"reflect"
	"strconv"
	"strings"

	"github.com/antha-lang/antha/antha/anthalib/data"
	"github.com/pkg/errors"
	"github.com/xitongsys/parquet-go/parquet"
)

// an internally used representation of Parquet data schema
type parquetSchema struct {
	*data.Schema
	rootElementName string
	isNullable      []bool // false -> the column should *not* be boxed as pointer when deserializing
}

// standard parquet-go schema root element name
const parquetGoRoot = "parquet_go_root"

func newParquetSchema(tableSchema *data.Schema) *parquetSchema {
	return &parquetSchema{
		Schema:          tableSchema,
		rootElementName: parquetGoRoot, // standard root element name - in order to make at least Parquet files generated by ourselves readable by parquet-go out of box
	}
}

func (ps *parquetSchema) nullable(columnIndex int) bool {
	// if we never set the isNullable field (eg on write) then we will treat as a nullable series
	return columnIndex >= len(ps.isNullable) || ps.isNullable[columnIndex]
}

// determines a field type for a dynamic data structure based on a column type
func (ps *parquetSchema) rowFieldType(columnIndex int) reflect.Type {
	column := ps.Columns[columnIndex]
	columnType := column.Type
	// a workaround for timestamp types: parquet-go is unable to read them directly, so reading then as int64
	if columnType.Kind() == reflect.Int64 {
		columnType = reflect.TypeOf(int64(0))
	}
	if ps.nullable(columnIndex) {
		//  parquet-go needs a pointer type here
		columnType = reflect.PtrTo(columnType)
	}
	return columnType
}

// converts parquetSchema to a JSON representation understandable by parquet-go
func (ps *parquetSchema) toJSON() (string, error) {
	root := make(map[string]interface{})

	// root element
	root["Tag"] = new(parquetTagBuilder).addName(ps.rootElementName).addInname(ps.rootElementName).addRequired(true).String()

	// fields
	fields := make([]interface{}, len(ps.Columns))
	for i := range ps.Columns {
		tag, err := ps.fieldTag(i)
		if err != nil {
			return "", err
		}

		fields[i] = map[string]string{"Tag": tag}
	}
	root["Fields"] = fields

	// building json
	json, err := json.Marshal(root)
	if err != nil {
		return "", err
	}

	return string(json), nil
}

// creates parquet tag for a dynamic struct field
func (ps *parquetSchema) fieldTag(columnIndex int) (string, error) {
	column := ps.Columns[columnIndex]
	// parquet tag builder
	var tagBuilder parquetTagBuilder
	// name parquet tag (Parquet column name)
	tagBuilder.addName(string(column.Name))
	// inname parquet tag (struct field name)
	tagBuilder.addInname(fieldName(columnIndex))

	// type tag
	// https://github.com/xitongsys/parquet-go#type
	switch column.Type {
	case reflect.TypeOf(false):
		tagBuilder.addType("BOOLEAN")
	case reflect.TypeOf(int32(0)):
		tagBuilder.addType("INT32")
	case reflect.TypeOf(int64(0)):
		tagBuilder.addType("INT64")
	case reflect.TypeOf(float32(0)):
		tagBuilder.addType("FLOAT")
	case reflect.TypeOf(float64(0)):
		tagBuilder.addType("DOUBLE")
	case reflect.TypeOf(""):
		tagBuilder.addType("UTF8").addEncoding("PLAIN_DICTIONARY")
	case reflect.TypeOf(data.TimestampMillis(0)):
		tagBuilder.addType("TIMESTAMP_MILLIS")
	case reflect.TypeOf(data.TimestampMicros(0)):
		tagBuilder.addType("TIMESTAMP_MICROS")
	default:
		return "", errors.Errorf("data type %v is not supported", column.Type)
	}

	// In future this can be adjusted/optimized for series that eg. do not have a nullability mask
	tagBuilder.addRequired(!ps.nullable(columnIndex))

	// finishing field parquet tag
	return tagBuilder.String(), nil
}

// for now, using autogenerated names like 'FieldN' for dynamic structs fields
func fieldName(index int) string {
	return "Field" + strconv.Itoa(index)
}

// a tool for building struct tags readable by Parquet reader/writer
type parquetTagBuilder struct {
	strings.Builder
}

func (b *parquetTagBuilder) addName(value string) *parquetTagBuilder {
	return b.addParam("name", value)
}

func (b *parquetTagBuilder) addInname(value string) *parquetTagBuilder {
	return b.addParam("inname", value)
}

func (b *parquetTagBuilder) addType(value string) *parquetTagBuilder {
	return b.addParam("type", value)
}

func (b *parquetTagBuilder) addEncoding(value string) *parquetTagBuilder {
	return b.addParam("encoding", value)
}

func (b *parquetTagBuilder) addRequired(isRequired bool) *parquetTagBuilder {
	if isRequired {
		return b.addParam("repetitiontype", "REQUIRED")
	}
	return b.addParam("repetitiontype", "OPTIONAL")
}

func (b *parquetTagBuilder) add(s string) *parquetTagBuilder {
	if _, err := b.WriteString(s); err != nil {
		panic(err)
	}
	return b
}

func (b *parquetTagBuilder) addParam(name string, value string) *parquetTagBuilder {
	if b.Len() > 0 {
		b.add(", ")
	}
	b.add(name).add("=").add(value)
	return b
}

// creates a dynamic struct type by a Table schema read from Parquet file
func rowStructFromSchema(schema *parquetSchema) reflect.Type {
	// creating fields
	fields := make([]reflect.StructField, len(schema.Columns))
	for i := range schema.Columns {
		fields[i] = reflect.StructField{
			Name: fieldName(i), // for now, using just generated field names (in order to avoid clashes)
			Type: schema.rowFieldType(i),
		}
	}

	// creating a dynamic struct type
	return reflect.StructOf(fields)
}

// transforming Parquet file metadata into schema
func schemaFromParquetMetadata(metadata *parquet.FileMetaData, columnNames []data.ColumnName) (*parquetSchema, error) {
	// currently using Parquet schema only; in future we might store something useful in metadata.KeyValueMetadata
	schema := metadata.Schema
	if len(schema) == 0 {
		return nil, errors.New("Empty schema")
	}

	// for now, we can handle plain schemas only (i.e. without nested types); such schemas consist of:
	// 1) root element
	columnsCount := int(*schema[0].NumChildren)
	if len(schema) != columnsCount+1 {
		return nil, errors.New("Schema is not plain")
	}

	// 2) list of other elements, each of them corresponds to one column
	columns := make([]data.Column, 0)
	isNullable := make([]bool, 0)
	for i := 0; i < columnsCount; i++ {
		element := schema[i+1]
		name := data.ColumnName(element.Name)

		if !doAddColumn(name, columnNames) {
			continue
		}

		columnType, repetitionType, err := columnTypeFromSchemaElement(element)
		if err != nil {
			return nil, err
		}
		isNullable = append(isNullable, repetitionType == parquet.FieldRepetitionType_OPTIONAL)
		columns = append(columns, data.Column{
			Name: name,
			Type: columnType,
		})
	}

	return &parquetSchema{data.NewSchema(columns), schema[0].Name, isNullable}, nil
}

// determines whether to read the column from Parquet
func doAddColumn(name data.ColumnName, columnNames []data.ColumnName) bool {
	// if no column names are specified by user, then reading all columns
	if len(columnNames) == 0 {
		return true
	}
	// otherwise, looking for this column name in the user-defined list
	for _, columnName := range columnNames {
		if name == columnName {
			return true
		}
	}
	return false
}

// nolint
// determines Go type to store values from Parquet column defined by schema element
func columnTypeFromSchemaElement(schemaElement *parquet.SchemaElement) (reflect.Type, parquet.FieldRepetitionType, error) {
	// 1) repeated (slice) fields aren't currently supported
	repetitionType := schemaElement.GetRepetitionType()
	switch repetitionType {
	case parquet.FieldRepetitionType_OPTIONAL, parquet.FieldRepetitionType_REQUIRED:
	//ok
	default:
		return nil, repetitionType, errors.Errorf("Unsupported: schema element '%s' has repetition type '%s'", schemaElement.Name, schemaElement.GetRepetitionType().String())
	}
	// 2) plain types only
	if schemaElement.NumChildren != nil {
		return nil, repetitionType, errors.Errorf("Unsupported: schema element '%s' has children", schemaElement.Name)
	}

	switch schemaElement.GetType() {
	case parquet.Type_BOOLEAN:
		// boolean
		return reflect.TypeOf(false), repetitionType, nil
	case parquet.Type_INT32:
		// int32
		if schemaElement.ConvertedType == nil {
			return reflect.TypeOf(int32(0)), repetitionType, nil
		}
		return nil, repetitionType, errors.Errorf("Unsupported: int32 schema element '%s' has converted type '%v'", schemaElement.Name, schemaElement.ConvertedType)
	case parquet.Type_INT64:
		// int64, time64 or timestamp32/64
		if schemaElement.ConvertedType == nil {
			return reflect.TypeOf(int64(0)), repetitionType, nil
		}
		switch *schemaElement.ConvertedType {
		case parquet.ConvertedType_TIMESTAMP_MILLIS:
			return reflect.TypeOf(data.TimestampMillis(0)), repetitionType, nil
		case parquet.ConvertedType_TIMESTAMP_MICROS:
			return reflect.TypeOf(data.TimestampMicros(0)), repetitionType, nil
		default:
			return nil, repetitionType, errors.Errorf("Unsupported: int64 schema element '%s' has converted type '%s'", schemaElement.Name, schemaElement.ConvertedType.String())
		}
	case parquet.Type_FLOAT:
		// float32
		return reflect.TypeOf(float32(0)), repetitionType, nil
	case parquet.Type_DOUBLE:
		// float64
		return reflect.TypeOf(float64(0)), repetitionType, nil
	case parquet.Type_BYTE_ARRAY:
		// string
		if schemaElement.ConvertedType == nil {
			return nil, repetitionType, errors.Errorf("Unsupported: byte array schema element '%s' has converted type 'nil'", schemaElement.Name)
		}
		switch *schemaElement.ConvertedType {
		case parquet.ConvertedType_UTF8:
			return reflect.TypeOf(""), repetitionType, nil
		default:
			return nil, repetitionType, errors.Errorf("Unsupported: byte array schema element '%s' has converted type '%s'", schemaElement.Name, schemaElement.ConvertedType.String())
		}
	default:
		return nil, repetitionType, errors.Errorf("Unsupported: schema element '%s' has type '%s'", schemaElement.Name, schemaElement.GetType().String())
	}
}
